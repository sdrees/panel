{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Langchain `PanelCallbackHandler` itself is not a widget or pane, but is useful for rendering and streaming output from Langchain Tools, Agents, and Chains as `ChatMessage` objects. It inherits from Langchain's [BaseCallbackHandler](https://python.langchain.com/docs/modules/callbacks/).\n",
    "\n",
    "#### Parameters:\n",
    "\n",
    "##### Core\n",
    "\n",
    "* **`instance`** (ChatFeed | ChatInterface): The ChatFeed or ChatInterface instance.\n",
    "* **`user`** (str): Name of the user who sent the message.\n",
    "* **`avatar`** (str | BinaryIO): The avatar to use for the user. Can be a single character text, an emoji, or anything supported by `pn.pane.Image`. If not set, uses the first character of the name.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basics\n",
    "\n",
    "To get started:\n",
    "\n",
    "1. Pass the instance of a `ChatFeed` or `ChatInterface` to `PanelCallbackHandler`.\n",
    "2. Pass the `callback_handler` as a list into `callbacks` when constructing Langchain objects.\n",
    "\n",
    "\n",
    "```python\n",
    "import panel as pn\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "pn.extension()\n",
    "\n",
    "\n",
    "def callback(contents, user, instance):\n",
    "    llm.predict(contents)\n",
    "\n",
    "\n",
    "instance = pn.chat.ChatInterface(callback=callback)\n",
    "callback_handler = pn.chat.PanelCallbackHandler(instance)\n",
    "\n",
    "llm = OpenAI(temperature=0, callbacks=[callback_handler])\n",
    "\n",
    "instance.servable()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async\n",
    "\n",
    "`async` can also be used:\n",
    "\n",
    "1. Prefix the function with `async`.\n",
    "2. Replace the `predict` call with `apredict`.\n",
    "3. Prefix the call with `await`.\n",
    "\n",
    "```python\n",
    "import panel as pn\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "pn.extension()\n",
    "\n",
    "\n",
    "async def callback(contents, user, instance):\n",
    "    await llm.apredict(contents)\n",
    "\n",
    "\n",
    "instance = pn.chat.ChatInterface(callback=callback)\n",
    "callback_handler = pn.chat.PanelCallbackHandler(instance)\n",
    "\n",
    "llm = OpenAI(temperature=0, callbacks=[callback_handler])\n",
    "\n",
    "instance.servable()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streaming\n",
    "\n",
    "To stream tokens from the LLM, simply set `streaming=True` when constructing the LLM.\n",
    "\n",
    "Note, `async` is not required to stream, but it is more efficient.\n",
    "\n",
    "```python\n",
    "import panel as pn\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "pn.extension()\n",
    "\n",
    "\n",
    "async def callback(contents, user, instance):\n",
    "    await llm.apredict(contents)\n",
    "\n",
    "\n",
    "instance = pn.chat.ChatInterface(callback=callback)\n",
    "callback_handler = pn.chat.PanelCallbackHandler(instance)\n",
    "\n",
    "llm = OpenAI(temperature=0, callbacks=[callback_handler], streaming=True)\n",
    "\n",
    "instance.servable()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents & Tools\n",
    "\n",
    "To differentiate between agents', tools', and other LLM output (i.e. automatically use corresponding avatars and names), be sure to also provide `callback_handler` to their constructors.\n",
    "\n",
    "Again, `async` is not required, but more efficient.\n",
    "\n",
    "```python\n",
    "import panel as pn\n",
    "from langchain.agents import AgentType, load_tools, initialize_agent\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "pn.extension()\n",
    "\n",
    "\n",
    "async def callback(contents, *args):\n",
    "    await agent.arun(contents)\n",
    "\n",
    "\n",
    "instance = pn.chat.ChatInterface(callback=callback)\n",
    "callback_handler = pn.chat.PanelCallbackHandler(instance)\n",
    "llm = OpenAI(temperature=0, callbacks=[callback_handler], streaming=True)\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm, callbacks=[callback_handler])\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    callbacks=[callback_handler],\n",
    ")\n",
    "\n",
    "instance.servable()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
